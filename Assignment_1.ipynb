{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stat-junda/Stat-359-Modern-Deep-Learning/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answering Fermi Questions\n",
        "\n",
        "This assignment consists of three parts.\n",
        "\n",
        "1. Basic usage of OpenAI's API and how to construct query calls\n",
        "2. Writing good prompts to get better output from ChatGPT\n",
        "3. Basics of the attention mechanism"
      ],
      "metadata": {
        "id": "5HxRzTn7wUVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the ! pip line of this cell if you get errors running cell 3.\n",
        "# You might get errors when running this. If you are able to run cell 3, then\n",
        "# you can ignore these errors.\n",
        "! pip install openai\n",
        "! pip install cohere tiktoken\n"
      ],
      "metadata": {
        "id": "bWAWt_F4xaes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33816c8b-ff25-4a00-8474-42e1f0b1fe79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.44-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m944.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, tiktoken, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed backoff-2.2.1 cohere-4.44 fastavro-1.9.3 importlib_metadata-6.11.0 tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1) OpenAI API\n",
        "\n",
        "Read through the documentation of OpenAI API. Start [here](https://github.com/openai/openai-python).\n",
        "\n",
        "\n",
        "You should have an API key. Place your API key in the left tool bar on Colab, by clicking on the tool item the shape of a key, labelled \"secrets\".\n",
        "\n",
        "Add a new secret.\n",
        "\n",
        "Give it the name \"**openai**\" and paste your key in the value section. Make sure to toggle Notebook access.\n",
        "\n"
      ],
      "metadata": {
        "id": "lfiRaFYLurON"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bTDtUtR1wCsm"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('openai')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI, ChatCompletion\n",
        "\n",
        "# Instantiate your OpenAI API client\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "BB0dHtQbwTb9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The key has been set. We are ready to query ChatGPT.\n",
        "# Fill out the functions below.\n",
        "# Do not batch queries.\n",
        "# Do not change the model from 'gpt-3.5-turbo'\n",
        "\n",
        "def basic_query(client: OpenAI, message: str, model: str = 'gpt-3.5-turbo'):\n",
        "  '''\n",
        "  Inputs:\n",
        "  `client`: Takes an OpenAI client object\n",
        "  `message`: The message to pass to the OpenAI LLM model\n",
        "  `model`: The model to use. Do not modify this\n",
        "\n",
        "  Returns:\n",
        "  An OpenAI response object to the message you have passed.\n",
        "  '''\n",
        "  messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": message}\n",
        "    ] # fill out the message payload\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    ) # placeholder\n",
        "\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "LEi50yIWt3mE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_response(responseObj: ChatCompletion) -> Dict[str, str]:\n",
        "    '''\n",
        "    Inputs:\n",
        "    `responseObj`: The response of the GPT chat.completions.create()\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of the following format:\n",
        "    {\n",
        "      'role': STRING representing the role attribute returned by the response obj\n",
        "      'content': STRING representation of GPT's response message,\n",
        "    }\n",
        "\n",
        "    Hint, run the basic_query() in another code block and observe the output structure.\n",
        "    That alone should be sufficient to make this function.\n",
        "    '''\n",
        "    # Extracting the last message from the response, which is the model's reply\n",
        "    last_message = responseObj.choices[0].message\n",
        "\n",
        "    # Constructing the output dictionary\n",
        "    out = {\n",
        "        'role': last_message.role,\n",
        "        'content': last_message.content\n",
        "    }\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "0vYTXlvXtA6E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN BUT DO NOT MODIFY THE CODE BELOW\n",
        "\n",
        "message = '''What is a Fermi Question.\n",
        "Explain it concisely and provide a brief example.'''\n",
        "\n",
        "responseObj = basic_query(client=client,\n",
        "                          message= message)\n",
        "\n",
        "parse_response(responseObj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgRTH0cysKVK",
        "outputId": "8a0e4255-3fbc-4838-da1d-8fdce75585c4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': 'A Fermi question is a type of estimation problem that involves making quick and rough calculations using logical reasoning and common sense, rather than relying on exact numbers or extensive research. It is named after the physicist Enrico Fermi. \\n\\nFor example, a Fermi question could be: \"How many piano tuners are there in New York City?\" To estimate this, one might consider the population of New York City, the average number of people per household, the percentage of households that own a piano, and the typical frequency of piano tuning. By making reasonable assumptions and performing simple calculations, an estimation can be made without needing to know the exact number.'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Part 2) Fermi Questions"
      ],
      "metadata": {
        "id": "1YC5y0io4sX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''\n",
        "How many tennis balls can fit on a Boeing 747?\n",
        "'''\n",
        "\n",
        "fermiResponseObj = basic_query(client, message=question)\n",
        "parse_response(fermiResponseObj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yDUFDiT5ETY",
        "outputId": "e704ade2-4c77-4c95-b8c2-ea766058e68e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': 'The exact number of tennis balls that can fit on a Boeing 747 would depend on various factors such as the size of the tennis balls, how they are arranged, and how much other cargo is already on the plane. However, to give you an estimate, the cargo hold of a Boeing 747-400 can typically hold around 22 shipping containers, with each container having a volume of about 135 cubic meters. If we assume that the tennis balls are packed tightly together and each ball has a diameter of 6.7 cm, we can estimate that around 6,000 tennis balls could fit in one container. Therefore, an approximate estimate would be that around 132,000 tennis balls (22 containers multiplied by 6,000 tennis balls) could fit on a Boeing 747-400. Please note that this is just a rough estimation and the actual number may vary.'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I ran the code, I got the following result:\n",
        "\n",
        "```\n",
        "The exact number of tennis balls that can fit on a Boeing 747 would depend on various factors, such as the size of the tennis balls, how they are packed, and whether any other cargo is being carried in the plane.\n",
        "Furthermore, there are different models of the Boeing 747 with varying cargo capacities.\n",
        "However, as a rough estimate, to visualize the capacity, let's assume we are using standard-sized tennis balls (approximately 6.7 cm in diameter)\n",
        "and considering only the cargo hold of a Boeing 747-400.\n",
        "\n",
        "The cargo hold of a Boeing 747-400 has a total volume of around 570 cubic meters. Assuming that each tennis ball has a volume of approximately 26.8 cubic centimeters, we can calculate an approximate number.\n",
        "\n",
        "570 cubic meters is equivalent to 570,000,000 cubic centimeters.\n",
        "\n",
        "Thus, the estimated number of tennis balls that can fit would be:\n",
        "\n",
        "570,000,000 cubic centimeters / 26.8 cubic centimeters ≈ 21,268,656 tennis balls.\n",
        "\n",
        "Please note that this is a simplified calculation and does not take into account any additional factors that may affect the total capacity of the aircraft or its weight limitations.\n",
        "```\n",
        "\n",
        "This answer is not good for a couple of reasons\n",
        "  - This seems like quite a relatively specific number rather than a range.\n",
        "  - The more acceptable approach is to compare volumes. This compares weights. This is actually telling us how many tennis balls will it take to weight the same as a 747.\n",
        "\n",
        "Your job is to make these estimates better with prompting. You should aim for a response that provides a reasonable range.\n",
        "\n",
        "E.g. How many tennis balls fit in a Boeing 747?\n",
        "\n",
        "Possible types of responses:\n",
        "\n",
        " - ~Between 100 and 200~. While true and obvious, this is not a very intelligent answer\n",
        " - ~60,000,000 tennis balls~. This answer provides no chain of thought.\n",
        " - Provided the diameter of a tennis ball is x, and the volume of the 747 is z, we estimate around 10^4 to 10^6 tennis balls can fit on a 747. (If your GPT gives this type of response, it would be considered an excellent response.)\n",
        "\n",
        "\n",
        "Your job is to come up with one single prompt, that will answer all fifty Fermi questions below. In reality, you will probably encounter some questions that it cannot solve no matter how you prompt it. That is OK. Try to create a prompt for GPT to yield as many reasonable results as you can. Be creative with your  prompt.\n",
        "\n",
        "\n",
        "**When testing out different prompts, only run it on 1 or 2 questions. Once you have decided on a prompt, go ahead and run it on the entire list.**\n"
      ],
      "metadata": {
        "id": "LjnPHtSr13Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = '''\n",
        "When answering Fermi questions, such as estimating quantities or numbers in various scenarios, it's important to focus on logical reasoning and approximation.\n",
        "Use known averages or typical values for measurements that are not specified.\n",
        "Explain your reasoning in steps, highlighting any assumptions you make.\n",
        "Always aim to provide answers in the form of a reasonable range to reflect the uncertainties involved in such estimations.\n",
        "Your answer should give a general idea rather than a precise figure, demonstrating the thought process behind arriving at that estimate.\n",
        "'''"
      ],
      "metadata": {
        "id": "mazud6Vi9rSW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "  'How many cups of coffee are consumed globally in a day?',\n",
        "  'Estimate the number of bricks used in the construction of the Great Wall of China.',\n",
        "  'How many grains of sand are on an average sized beach?',\n",
        "  'Estimate the total weight of all elephants in Africa in kilograms.',\n",
        "  'How many breaths does an average person take in a year?',\n",
        "  'Estimate the number of hours the average person spends watching TV in a month.'\n",
        "  ]"
      ],
      "metadata": {
        "id": "4XIZTMCKuQX_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THESE QUESTIONS\n",
        "questions = [\n",
        "  'How many cups of coffee are consumed globally in a day?',\n",
        "  'Estimate the number of bricks used in the construction of the Great Wall of China.',\n",
        "  'How many grains of sand are on an average sized beach?',\n",
        "  'Estimate the total weight of all elephants in Africa in kilograms.',\n",
        "  'How many breaths does an average person take in a year?',\n",
        "  'Estimate the number of hours the average person spends watching TV in a month.',\n",
        "  'How many blades of grass are on a soccer field?',\n",
        "  'Estimate the number of cells in the human brain.',\n",
        "  'How many total hours of sleep does a person get in a year?',\n",
        "  'Estimate the number of text messages sent globally in a minute.',\n",
        "  'How many McDonalds are there in the United States?',\n",
        "  'Estimate the total weight of all the plastic produced in a year.',\n",
        "  'How many footsteps does an average person take in a day?',\n",
        "  'Estimate the daily number of people who visit a large shopping mall.',\n",
        "  'How many gigabytes of data are transferred on the internet in an hour?',\n",
        "  'Estimate the number of busses in the United States.',\n",
        "  'How many trumpet players are there in the world?',\n",
        "  'Estimate the total length of all the rivers in Asia in kilometers.',\n",
        "  'How many calories does the average person consume on Thanksgiving Day?',\n",
        "  'Estimate the number of bacteria on an average human hand.',\n",
        "  'How many books are in all libraries in the United States',\n",
        "  'Estimate the number of atoms in a grain of sand.',\n",
        "  'How many cups of tea are consumed daily around the world?',\n",
        "  'Estimate the total weight of all the paper produced in a year.',\n",
        "  'How many blades of wheat are in a small loaf of bread?',\n",
        "  'Estimate the number of hairs on an average cat.',\n",
        "  'How many breaths does a newborn baby take in an hour?',\n",
        "  'Estimate the number of footsteps taken during a marathon.',\n",
        "  'How many ants are there in a large ant colony?',\n",
        "  'Estimate the number of stars visible in the night sky from a city.',\n",
        "  'How many tweets are sent worldwide in a minute?',\n",
        "  'Estimate the total weight of all the apples sold in a month.',\n",
        "  'How many atoms are there in a human cell?',\n",
        "  'Estimate the number of raindrops in a light rain shower.',\n",
        "  'How many total minutes of music are streamed on Spotify in a day?',\n",
        "  'Estimate the number of computer mice in use globally.',\n",
        "  'How many light bulbs are in Times Square during New Years Eve?',\n",
        "  'Estimate the total length of all the fiber optic cables under the ocean.',\n",
        "  'How many wheels are there in the world?',\n",
        "  'Estimate the number of grains of rice in a 5 kilogram bag.',\n",
        "  'How many blades of grass are in an 18 hole golf course?',\n",
        "  'Estimate the number of words in an average length novel.',\n",
        "  'How many breaths does a person take during a one hour yoga session?',\n",
        "  'Estimate the total weight of all the plastic bottles used in a year.',\n",
        "  'How many footsteps does the average person take in a lifetime?',\n",
        "  'Estimate the number of atoms in a cup of water.',\n",
        "  'How many grains of salt are there in a typical salt shaker?',\n",
        "  'Estimate the total length of all the subway tracks in New York City.',\n",
        "  'How many iPhones are there in the world?',\n",
        "  'Estimate the number of words spoken in the United States in one day.'\n",
        "]"
      ],
      "metadata": {
        "id": "yBy1gA3W96Pt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_all(PROMPT: str, questions: list) -> list:\n",
        "    answers = []\n",
        "\n",
        "    for question in questions:\n",
        "        # Combine the prompt with the question\n",
        "        combined_query = PROMPT + '\\n\\n' + question\n",
        "\n",
        "        # Send the combined query to the basic_query function\n",
        "        responseObj = basic_query(client, message=combined_query)\n",
        "\n",
        "        # Parse the response and add it to the answers list\n",
        "        parsed_response = parse_response(responseObj)\n",
        "        answers.append(parsed_response)\n",
        "\n",
        "    return answers\n"
      ],
      "metadata": {
        "id": "P2b2Rl93wrGf"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_all(PROMPT: str, questions: list) -> list:\n",
        "  '''\n",
        "  Inputs:\n",
        "  `PROMPT`: your prompt as a string\n",
        "  `questions`: the list of questions from above\n",
        "\n",
        "  Returns:\n",
        "  A list of dictionary responses containing 'role' and 'content' keys for each question-response.\n",
        "\n",
        "\n",
        "  Write a function to take in your prompt, append it to all the questions\n",
        "  to send to the API with basic query. Do not use batching.\n",
        "\n",
        "  Return your responses as dictionaries like above\n",
        "  into a list called `answers`.\n",
        "\n",
        "  You may use the functions you have written above:\n",
        "  basic_query() and parse_response()\n",
        "\n",
        "  '''\n",
        "\n",
        "  ## WRITE YOUR FUNCTION HERE\n",
        "\n",
        "  answers = [] # this is a placeholder\n",
        "\n",
        "  # for testing purposes, you can evaluate your prompts on a single question.\n",
        "  # once you are happy with your prompt, you can remove the [:1] below, to\n",
        "  # loop over the entire question list.\n",
        "  for question in questions[:1]:\n",
        "    pass # fill in the for loop, remove the pass statement\n",
        "\n",
        "\n",
        "  return answers\n"
      ],
      "metadata": {
        "id": "F7uQqQTqECAr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN BUT DO NOT MODIFY THIS CODE BLOCK.\n",
        "# This code block may take a while to run\n",
        "\n",
        "answer_all(PROMPT=PROMPT, questions=questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSmFhv2ZKeKp",
        "outputId": "064bcad0-8bc3-44e2-daa8-1384726f56bc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'assistant',\n",
              "  'content': \"To estimate the number of cups of coffee consumed globally in a day, we can break down the problem into smaller, more manageable components.\\n\\n1. Global population: According to the United Nations, the current global population is approximately 7.9 billion people.\\n\\n2. Coffee consumption per capita: This is a bit trickier to estimate, as coffee consumption varies by country and culture. However, we can make an educated guess based on known coffee-drinking habits in some regions. Let's assume an average consumption of 2 cups per day per person.\\n\\n3. Accounting for non-coffee drinkers: Not everyone drinks coffee, so we need to account for those who don't consume any coffee. Let's assume that 25% of the global population does not drink coffee.\\n\\n4. Estimating the percentage of coffee consumed as brewed coffee: Different coffee products such as instant coffee, espresso, and specialty coffee drinks can all be considered as coffee consumption. However, let's assume that 75% of coffee consumption is in the form of brewed coffee.\\n\\nNow let's calculate the estimated number of cups of coffee consumed globally in a day:\\n\\nGlobal population: 7.9 billion people\\nAssuming 75% of coffee consumption is brewed coffee: 7.9 billion * 0.75 = 5.925 billion people\\n\\nCoffee consumption per capita: 2 cups per day per person\\n5.925 billion people * 2 cups per day = 11.85 billion cups of coffee consumed\\n\\nAccounting for non-coffee drinkers: 25% of the global population does not drink coffee\\n11.85 billion cups * (1 - 0.25) = 8.8875 billion cups\\n\\nTherefore, a reasonable estimate for the number of cups of coffee consumed globally in a day is around 8.9 billion cups of coffee.\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"To estimate the number of bricks used in the construction of the Great Wall of China, we can make a few assumptions and approximations:\\n\\n1. Length of the Great Wall: The commonly accepted length of the Great Wall is around 13,170 miles (21,196 kilometers).\\n\\n2. Width and Height of the Wall: The average width of the wall is approximately 15 feet (4.6 meters), while the height varies between 15 to 30 feet (4.6 to 9.1 meters).\\n\\n3. Space for Mortar: Assuming a typical brick size of 8 x 4 x 2 inches (20 x 10 x 5 cm) and taking into account the space for mortar between bricks, we can estimate that each brick covers an area of approximately 0.07 square feet (0.0065 square meters).\\n\\nBased on these assumptions, we can estimate the number of bricks used as follows:\\n\\n1. Calculate the total surface area of the Great Wall: \\nSurface Area = Length x Width x Height\\n\\nFor instance, let's assume an average height of 20 feet (6.1 meters) and an average width of 15 feet (4.6 meters):\\n\\nSurface Area = 13,170 miles x 5280 feet/mile x 15 feet x 20 feet\\nSurface Area = approximately 19.6 billion square feet (1.82 billion square meters)\\n\\n2. Calculate the number of bricks required: \\nNumber of Bricks = Surface Area / Brick Area\\n\\nUsing the average brick area of 0.07 square feet (0.0065 square meters), we can estimate the number of bricks:\\n\\nNumber of Bricks = 19.6 billion square feet / 0.07 square feet\\nNumber of Bricks = approximately 280 billion bricks\\n\\nTherefore, based on our estimations, the number of bricks used in the construction of the Great Wall of China could range from around 280 billion bricks. Keep in mind that this estimate is subject to various assumptions and approximations, and the actual number may vary.\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"To estimate the number of grains of sand on an average-sized beach, we can break down the problem into several steps.\\n\\nStep 1: Estimate the area of an average-sized beach.\\nWe can start by assuming the dimensions of a typical beach. Let's say it has a length of about 1 kilometer (1000 meters) and a width of about 100 meters. This gives us an estimated area of 100,000 square meters.\\n\\nStep 2: Estimate the thickness of the sand layer.\\nThe thickness of the sand layer can vary across different beaches. We will make the assumption that the average thickness is about 1 meter (100 centimeters) for our estimation.\\n\\nStep 3: Estimate the average volume of sand per cubic meter.\\nAgain, this value can vary depending on the beach, but for our estimation, we'll assume an average value. Let's say the sand occupies about 75% of the volume of a cubic meter.\\n\\nStep 4: Convert the volume of sand to the number of grains.\\nTo estimate the number of grains, we need an approximation of the volume occupied by a single grain of sand. Since sand grains vary in size, we'll use an average value. A common approximate value is 0.5 millimeters cubed (0.0005 cubic centimeters) for a single grain.\\n\\nStep 5: Calculate the number of grains of sand.\\nWe can now calculate the number of grains using the volume estimation from step 3 and the volume occupied by a single grain from step 4.\\n\\nEstimated number of grains of sand = (volume of sand) / (volume of a grain)\\n\\nUsing the assumptions and approximations mentioned above, we can estimate the number of grains of sand on an average-sized beach to be:\\n\\nEstimated number of grains of sand = (100,000 square meters * 100 centimeters * 0.75) / (0.0005 cubic centimeters)\\n\\nSimplifying this equation gives us an estimated number of grains of sand on an average-sized beach.\\n\\nKeep in mind that this estimation is based on assumptions and average values, so the actual number of grains may vary significantly. Therefore, it's important to consider this as a rough estimate with a large range of uncertainty.\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"To estimate the total weight of all elephants in Africa, we can break down the problem into several steps.\\n\\n1. Estimate the population of elephants in Africa: According to the African Elephant Specialist Group, there are approximately 415,000 elephants in the wild in Africa. However, this number may vary, so we can round it to 400,000 for simplicity.\\n\\n2. Estimate the average weight of an adult elephant: Adult elephants can weigh anywhere between 2,700 to 6,000 kilograms. Let's assume an average of 4,000 kilograms for our estimation. \\n\\n3. Calculate the total weight: By multiplying the estimated population of elephants (400,000) by the average weight per elephant (4,000 kilograms), we find that the total weight of all elephants in Africa is roughly 1,600,000,000 kilograms or 1.6 billion kilograms.\\n\\nHowever, it's important to note that this estimation comes with a large degree of uncertainty. Elephants' weight can vary significantly based on their age, gender, and environmental factors. Additionally, the actual population of elephants in Africa is not precisely known. Therefore, it is advisable to view this estimation as a rough approximation rather than an exact figure.\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"To estimate the number of breaths an average person takes in a year, we can make a few reasonable assumptions and calculations.\\n\\nFirst, let's consider the number of breaths taken in a minute. On average, a person takes around 12-20 breaths per minute at rest. Let's take a conservative estimate of 15 breaths per minute.\\n\\nSo, in an hour, a person would take 15 breaths/minute * 60 minutes = 900 breaths.\\n\\nNow, let's consider how many hours a person is usually awake in a day. The average person sleeps for about 8 hours a day, which means they are awake for 16 hours.\\n\\nTherefore, the number of breaths in a day would be 900 breaths/hour * 16 hours = 14,400 breaths.\\n\\nNow, to calculate the number of breaths in a year, we'll assume there are 365 days in a year.\\n\\nSo, the estimated number of breaths in a year would be 14,400 breaths/day * 365 days/year = 5,256,000 breaths per year.\\n\\nHowever, it's important to remember that this estimation can vary based on factors such as physical activity, breathing conditions, and individual differences. Therefore, we should consider this estimate as a rough range rather than an exact figure.\"},\n",
              " {'role': 'assistant',\n",
              "  'content': \"To estimate the number of hours the average person spends watching TV in a month, we can use some logical reasoning and approximation.\\n\\nFirst, let's consider how many hours are typically available in a month. Assuming an average of 30 days in a month, and 24 hours in a day, we have approximately 720 hours in a month.\\n\\nNext, we need to consider how much time the average person might spend on different activities throughout the day. Since we're estimating TV watching, we can consider that people spend time sleeping, working, doing chores, and engaging in other hobbies or activities. Let's assume that, on average, people spend around 8 hours sleeping and 8 hours working each day. This leaves us with around 8 hours for leisure activities, including watching TV.\\n\\nNow, we need to consider how often people engage in other leisure activities. Let's assume that people spend about half of their free time watching TV, while the rest is spent on other hobbies, socializing, exercising, or doing other recreational activities.\\n\\nBased on these assumptions, we can estimate that the average person spends around 4 hours per day (8 hours of leisure time divided by 2) watching TV. \\n\\nMultiplying this estimate by the number of days in a month, we get an estimate of approximately 120 hours (4 hours per day multiplied by 30 days) that the average person spends watching TV in a month.\\n\\nAs with any estimation, it's important to remember that individual habits can vary widely. Some people may watch much more or less TV than the average, so this estimate is a general approximation.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3) Implementing Basic Attention\n",
        "\n",
        "Finish this implementation of the attention mechanism. Your result should be an attention matrix with 4 rows and 3 columns.\n",
        "\n",
        "Your job is to implement the `get_attention()` function"
      ],
      "metadata": {
        "id": "7I7GYbNvHGI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import random\n",
        "from numpy import dot\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "class BasicAttention:\n",
        "  def __init__(self):\n",
        "    # Assume these word embeddings\n",
        "    self.word_1 = np.array([1, 0, 0])\n",
        "    self.word_2 = np.array([0, 1, 0])\n",
        "    self.word_3 = np.array([1, 1, 0])\n",
        "    self.word_4 = np.array([0, 0, 1])\n",
        "\n",
        "    # Place the words into an array\n",
        "    self.words = np.array([self.word_1, self.word_2, self.word_3, self.word_4])\n",
        "\n",
        "    # Simulate the weight matrices\n",
        "    # In an actual model, these matrices are learned via optimization\n",
        "    rng = random.RandomState(seed=42)\n",
        "    self.W_Q = rng.randint(3, size=(3, 3))\n",
        "    self.W_K = rng.randint(3, size=(3, 3))\n",
        "    self.W_V = rng.randint(3, size=(3, 3))\n"
      ],
      "metadata": {
        "id": "_1D0VNyBHKoB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attention(self) -> np.ndarray:\n",
        "    '''\n",
        "    Use the self.words, self.W_Q, self.W_K, self.W_V matrices\n",
        "    and return an attention as a np.ndarray.\n",
        "\n",
        "    You may use scipy and numpy.\n",
        "    In particular, you may use the softmax import from scipy.\n",
        "\n",
        "    Your result should be an attention matrix with 4 rows and 3 columns.\n",
        "    '''\n",
        "\n",
        "    attn = [] # placeholder\n",
        "\n",
        "    return attn"
      ],
      "metadata": {
        "id": "ctLtGHhGyUBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attention(self) -> np.ndarray:\n",
        "    # Step 1: Calculate Q, K, V matrices\n",
        "    Q = dot(self.words, self.W_Q)\n",
        "    K = dot(self.words, self.W_K)\n",
        "    V = dot(self.words, self.W_V)\n",
        "\n",
        "    # Step 2: Compute the dot product of Q and the transpose of K,\n",
        "    # then apply softmax to get attention scores\n",
        "    attention_scores = softmax(dot(Q, K.T), axis=1)\n",
        "\n",
        "    # Step 3: Multiply the attention scores with V to get the final attention output\n",
        "    attn = dot(attention_scores, V)\n",
        "\n",
        "    return attn\n"
      ],
      "metadata": {
        "id": "cz4dBiR-yOZu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn = BasicAttention()\n",
        "print(attn.get_attention())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "Fi2rcmpxHnUx",
        "outputId": "2c8bd180-602d-4344-cae6-7481a3cb34bc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'BasicAttention' object has no attribute 'get_attention'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d079076bc8c0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'BasicAttention' object has no attribute 'get_attention'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE\n",
        "\n",
        "### Due to the generative nature of ChatGPT, your answers can be stochastic when run at different times and may differ depending on your inputs. It is important that you run the code for you to see your response.\n",
        "\n",
        "### Before submitting this assignment, RUN and KEEP the output results on this notebook. If you do not produce or keep these outputs, then the code will be run when it is being graded. Then you will be graded on the outputs from that run.\n",
        "\n",
        "### Best to run your code beforehand, so you know what you are submitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "a_DOk7bE6hsg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoQfqnerK-_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}