# Stat 359 Winter 2024
Stat 359 course materials



# Course Lectures 

Lecture notes can be found on the course Canvas website. 


| Lecture                  |  Date | Material | Readings                
|--------------------------|-------|----------|----------------------------|
| Week 1, Thursday         | January 4 |   Introduction  | [Perplexity](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/), [Perplexity 2](https://web.stanford.edu/~jurafsky/slp3/3.pdf), [Linear Models](https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf)  |
| Week 2, Tuesday           | January 9  | Attention |  [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf), [Attention Mechanisms](https://lilianweng.github.io/posts/2018-06-24-attention/), [Attention with code](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html), [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) |
| Week 2. Thursday       | January 11 | Transformers |  [Intro to Transformers](https://arxiv.org/pdf/2304.10557.pdf), [Discussion](https://www.columbia.edu/~jsl2239/transformers.html), [Blog post](https://peterbloem.nl/blog/transformers), [Skip connections](https://theaisummer.com/skip-connections/), [Layer normalization](https://www.kaggle.com/code/halflingwizard/how-does-layer-normalization-work), [Byte-Pair Encoding](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt) |
| Week 3, Tuesday            | January 16 | Coding a transformer |  [Code example](https://buomsoo-kim.github.io/attention/2020/04/21/Attention-mechanism-19.md/) |
| Week 3, Thursday         | January 18| BERT, GPT, LLAMA | [Annotated GPT 2](https://jalammar.github.io/illustrated-gpt2/),  [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), [Adversarial attacks on GPT-2](https://arxiv.org/abs/2012.07805) [LLAMA Paper](https://scontent-ord5-1.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=it_GnOgZ1hMAX_qDhzS&_nc_ht=scontent-ord5-1.xx&oh=00_AfCZyg0NnnD2SfBipL7DBQ467rntvBHugEZo7maieJZNTQ&oe=65ACEFE2), [BERT](https://arxiv.org/pdf/1810.04805.pdf), [Understanding BERT](https://jalammar.github.io/illustrated-bert/)|
| Week 4, Tuesday            | January 23| Prompt Tuning, chain of thought, hindsight chain of thought, backwards chain of thought, Graph of Thought, Tree of Thought, Training Chain-of-Thought via Latent-Variable Inferenc, 
prompt engineering | [Language Models are Few Shot Learners](https://arxiv.org/abs/2005.14165), [Model Calibration](https://arxiv.org/abs/2012.15723), [Zero shot chain of thought](https://arxiv.org/abs/2205.11916), [LLMs are human-level prompt engineers](https://arxiv.org/abs/2211.01910), [Tree of Thought](https://arxiv.org/abs/2305.10601), [Chain of verification](https://arxiv.org/abs/2309.11495), [Chain of hindsight](https://arxiv.org/abs/2302.02676), [Promptbreeder](https://arxiv.org/abs/2309.16797), [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide?tab=readme-ov-file), [Open-AI Prompting Guide](https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results)  |
| Week 4, Thursday          | January 25| Fine tuning, parameter-efficient fine tuning, LORA, SFT, Neftune, quantization |   |
| Week 5, Tuesday        | January 30 | Hugging face, fine tuning LLAMA    |  |
| Week 5, Thursday          | February 1| RAG, when to use RAG vs SFT, lexacagraphical vs semantic search, sentence transformers, Retrieval transofrmers and long term memory in transformers, RAG Code. | |
| Week 6, Tuesday        | February 6| ChatGPT and RLHF, rejection sampling, DPO, Gopher Cite  | |
| Week 6, Thursday       | February 8| Asking questions about images. Conditional layer norm, FILM, CLIP, BLIP, LAVA  |  |
| Week 7, Tuesday           | February 13| Diffusion models, DDPM, classifier-free guidance |   |
| Week 7, Thursday       | February 15| Diffusion model code, some diffusion model tricks   | |
| Week 8, Tuesday       | February 20| Stable Diffusion, tuning stable diffusion, Brianâ€™s code  |   |
| Week 8, Thursday   | February 22| Frontiers, using LLMs to help diffusion models by planning out images. Instance recognition and inserting new objects %s tricks. Consistency models, SD Edit,  Diffusion in robotics.                                      | |
| Week 9, Tuesday |  February 27| Presentations  | |
| Week 9, Thursday   |  February 29| Presentations |  |
| Week 10, Tuesday   |  March 5th| Presentations  |  |



# Homeworks and Due Dates


| Project title                  | Date released | Due date                
|--------------------------------|---------------|-------------------------|
|   Assignment 1       | Jan 9   | Jan 25  |
|     Assignment 2      |  Jan 30   | Feb 15  |
| Final presentation topic proposals |       |  Feb 15   | 
|  Final presentations        |       | Feb 27  |
